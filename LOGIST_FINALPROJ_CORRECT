#################################
#                               #
#       MSA Class of 2019       #
#                               #
#      Logistic Regression      #
#        Final Project          #
#        Orange Team 2          #
#                               #
#################################

#install.packages(c('expsmooth','lmtest','zoo','seasonal','haven','fma','gmodels','car','tseries','descr','forecast','brglm2','moments'))
library(car)
library(gmodels)
library(forecast)
library(haven)
library(fma)
library(descr)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(brglm2)
library(moments)
library(caret)
#install.packages('')
options(scipen=999) # Improve readability of parameter estimates

file.dir <- 'C:\\Users\\chels\\Desktop\\MSA\\Fall 1\\Logistic Regression\\Final_Project\\' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -Win_Bid)
summary(construction) # Summarize to check for missing values and descriptive statistics

#construction_train <- construction[1:380,] # Partition 70% percent of data into training set (if doing 80/20, this would be 1:434)
#construction_valid <- construction[381:543,] # Partition 30% of data into validation set (if doing 80/20, this would be 435:543)

##creating partitions randomly
#install.packages('caret')
library('caret')
##creating partitions randomly
set.seed(1452)
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE)
construction_train <- construction[inTrain,] 
construction_valid <- construction[-inTrain,]


control <- glm.control(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully

construction_ref <- glm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Sector+ Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_C + Competitor_D + Competitor_E + Competitor_F + Competitor_G + Competitor_H + Competitor_I + Competitor_J, data = construction_train, family = binomial(link = "logit"))#control.glm = control)
summary(construction_ref)
vif(construction_ref) # High VIF values for Estimated_Cost_Millions, Bid_Price_Millions, and Winning_Bid_Price_Millions,

construction_ref <- glm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Sector+Region_2 + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F  + Competitor_H + Competitor_I + Competitor_J, data = construction_train, family = binomial(link = "logit"))#control.glm = control)
summary(construction_ref)
vif(construction_ref)# No more multicollinearity present


hist(construction$Competitor_C, labels = TRUE) # Bid on 5.6% of total projects
hist(construction$Competitor_D, labels = TRUE) # Bid on 10.6% of total projects
# All other variables seem to exhibit appropriate distributions. None seem to require being binned into categories, for example...
hist(construction$Bid_Price__Millions_) # Replace variable as needed to generate histograms

# Check for skewness and kurtosis

for (i in c(1,2,3,6,7,8,9,10,11,12,13,14,15,16,17,18,19)) {
  if (skewness(construction[,i]) > 2) {
    print(skewness(construction[,i]))
  }
} # Competitors, C, D, and G all have high values here

for (i in c(1,2,3,6,7,8,9,10,11,12,13,14,15,16,17,18,19)) {
  if (kurtosis(construction[,i]) > 5) {
    print(kurtosis(construction[,i]))
  }
} # Five variables of interest - Competitors C, D, and G, Cost After Eng. Estimate, and Bid Win Diff

# Would recommend at least dropping Competitors C and D, can discuss further


##possible outliers...need to recheck in the model
boxplot(construction_train$Estimated_Years_to_Complete)
construction_train$Estimated_Years_to_Complete2[construction_train$Estimated_Years_to_Complete>15]

boxplot(construction_train$Bid_Win_Difference)
construction_train$Bid_Win_Difference[construction_train$Bid_Win_Difference>20]

boxplot(construction_train$Cost_After_Engineering_Estimate_)
boxplot(construction_train$Number_of_Competitor_Bids)


##Recategorizing Region for training:
class(construction_train$Region_of_Country)

prop.table(table(construction_train$Region_of_Country, construction_train$Won),margin = 1)
table(construction_train$Region_of_Country, construction_train$Won)

construction_train$Region_2[construction_train$Region_of_Country == 'Mid-west'] <- "Region 1"
construction_train$Region_2[construction_train$Region_of_Country == 'Northeast'] <- "Region 1"
construction_train$Region_2[construction_train$Region_of_Country == 'Southeast'] <- "Region 2"
construction_train$Region_2[construction_train$Region_of_Country == 'Southwest'] <- "Region 1"
construction_train$Region_2[construction_train$Region_of_Country == 'West'] <- "Region 2"

prop.table(table(construction_train$Region_2, construction_train$Won),margin = 1)
table(construction_train$Region_2, construction_train$Won)


##Recategorizing Region for validation:
class(construction_valid$Region_of_Country)

prop.table(table(construction_valid$Region_of_Country, construction_valid$Won),margin = 1)
table(construction_valid$Region_of_Country, construction_valid$Won)

construction_valid$Region_2[construction_valid$Region_of_Country == 'Mid-west'] <- "Region 1"
construction_valid$Region_2[construction_valid$Region_of_Country == 'Northeast'] <- "Region 1"
construction_valid$Region_2[construction_valid$Region_of_Country == 'Southeast'] <- "Region 2"
construction_valid$Region_2[construction_valid$Region_of_Country == 'Southwest'] <- "Region 1"
construction_valid$Region_2[construction_valid$Region_of_Country == 'West'] <- "Region 2"

prop.table(table(construction_valid$Region_2, construction_valid$Won),margin = 1)
table(construction_valid$Region_2, construction_valid$Won)


##Recategorizing Sector for training:
class(construction_train$Sector)

prop.table(table(construction_train$Sector, construction_train$Won),margin = 1)
table(construction_train$Sector, construction_train$Won)

construction_train$Sector2 <- 'Sector 2'
construction_train$Sector2[construction_train$Sector == '4'] <- "Sector 4"
construction_train$Sector2[construction_train$Sector == '5'] <- "Sector 5"
construction_train$Sector2[construction_train$Sector == '6'] <- "Sector 6"

prop.table(table(construction_train$Sector2, construction_train$Won),margin = 1)
table(construction_train$Sector2, construction_train$Won)

##Recategorizing Sector for validation:
class(construction_valid$Sector)

prop.table(table(construction_valid$Sector, construction_valid$Won),margin = 1)
table(construction_valid$Sector, construction_valid$Won)

construction_valid$Sector2 <- 'Sector 2'
construction_valid$Sector2[construction_valid$Sector == '4'] <- "Sector 4"
construction_valid$Sector2[construction_valid$Sector == '5'] <- "Sector 5"
construction_valid$Sector2[construction_valid$Sector == '6'] <- "Sector 6"

prop.table(table(construction_valid$Sector2, construction_valid$Won),margin = 1)
table(construction_valid$Sector2, construction_valid$Won)


#############################model building#########################################################################################
install.packages('brglm')
install.packages('MASS')
install.packages('tidyverse')
install.packages('caret')
library(caret)
library(brglm)
library(tidyverse)
library(MASS)
########Model 1 with Sector and Region_2 to eliminate multicollinearity w/o Estimated_Cost__Millions_ + Estimated_Years_to_Complete ######
construction_ref <- glm(Won ~  Region_2 +Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Sector2 + Competitor_A + Competitor_B + Competitor_E + Competitor_F  +
                          Competitor_H + Competitor_I + Competitor_J, data = construction_train,
                        family = binomial(link = "logit"))#control.glm = control)
summary(construction_ref)
backwards = step(construction_ref, trace = 0)
#AIC = 226
forwards
nothing <- glm(Won ~ 1,data = construction_train,family=binomial)
step(nothing,
     scope=list(lower=formula(nothing),upper=formula(construction_ref)), direction="forward")
#forward= same as backwards 


#same model backwards and forwards using AIC
anova(backwards,construction_ref, test ='LRT')
# high p-value means that new model is adequate 

########Model 2: without sector#########
construction_ref2 <- glm(Won ~ Region_of_Country +Estimated_Cost__Millions_ + Estimated_Years_to_Complete+
                            Competitor_A + Competitor_B + Competitor_E + Competitor_F  +
                           Competitor_H + Competitor_I + Competitor_J, data = construction_train,
                        family = binomial(link = "logit"))#control.glm = control)
summary(construction_ref2)#
backwards2 = step(construction_ref2)
anova(backwards2,construction_ref2, test = 'LRT')
#better than reference
step(nothing,
     scope=list(lower=formula(nothing),upper=formula(construction_ref2)), direction="forward")
#same as backwords AIC = 230

#####Model 3 regular with region_of_country and sector#######
construction_ref3 <- glm(Won ~  Region_of_Country +Sector+ Estimated_Cost__Millions_ + Estimated_Years_to_Complete+
                          Competitor_A + Competitor_B + Competitor_E + Competitor_F  +
                          Competitor_H + Competitor_I + Competitor_J, data = construction_train,
                        family = binomial(link = "logit"))#control.glm = control)
summary(construction_ref3)
backwards3 = step(construction_ref3)
#AIC 213
#forwards
nothing <- glm(Won ~ 1,data = construction_train,family=binomial)
step(nothing,
     scope=list(lower=formula(nothing),upper=formula(construction_ref3)), direction="forward")
anova(backwards3, construction_ref3, test = 'LRT')
#forward= same as backwards 
####ROC CURVES to check better model####
# the predicted probabilities go first, the actual outcomes (as a factor) second
pred <- prediction(fitted(backwards), factor(backwards$y))
pred2 <- prediction(fitted(backwards2), factor(backwards2$y))
pred3<- prediction(fitted(backwards3), factor(backwards3$y))
# then in performance, "measure" is the y-axis, and "x.measure" is the x-axis
# for a roc curve, we want tpr vs. fpr. "sens" and "spec" also work
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
perf2 <- performance(pred2, measure = "tpr", x.measure = "fpr")
perf3 <- performance(pred3, measure = "tpr", x.measure = "fpr")
# then we can plot
plot(perf, colorize = TRUE)
plot(perf2, add = TRUE, colorize = TRUE)
plot(perf3, add = TRUE, colorize = TRUE)
# add 45-degree line (random guessing)
abline(a = 0, b = 1, lty = 2)
# AUC
auc <- performance(pred, measure = "auc")@y.values
auc
#remove REGION, COMP. F,H,I P-vlaues not sig and remove 

####FINAL MODEL is built off of one######
final_model <- glm(Won ~   Sector2+ Estimated_Cost__Millions_ + 
                     Competitor_B + Competitor_E  +
                     Competitor_J, data = construction_train,
                   family = binomial(link = "logit"))#control.glm = control)
anova(final_model,construction_ref, test = 'LRT')



####Comparing Scenarios!
summary(compare_set)
new1 <- data.frame(Sector2 = c("Sector 6","Sector 2"), Estimated_Cost__Millions_ = c(145.8, 145.8), 
                   Competitor_B = c(0,0), 
                   Competitor_E = c(0,0), Competitor_J = c(1,0))

exp(predict(final_model, newdata = new1, type = "link")) # Gets the prediction for each individual new test case.

exp(diff(predict(final_model, newdata = new1, type = "link"))) # Interpretation of test cases - An average person is 6.86 times less likely to have an annuity than someone who is average except for having a CD with balance $20,000 and an MM.

# Probabilities
diff(predict(final_model, newdata = new1, type = "response"))



#########################   GOODNESS OF FIT final_model ########################################
#test for linear separation
final_model_sep <- glm(Won ~ Won ~   Sector2+ Estimated_Cost__Millions_ + 
                         Competitor_B + Competitor_E  +
                         Competitor_J,
                             data = construction_train,
                             family = binomial(link = "logit"),
                             method = "detect_separation")
construction_ref3_sep
#result: FALSE, conclude NO linear separation

#create dataframe of variables in final model: construction_train_keep
keep_vars3 <- c('Won','Sector2','Estimated_Cost__Millions_',
                  'Competitor_B','Competitor_E',
                  'Competitor_J')
construction_train_keep3 <- construction_train[, which(names(construction_train) %in% keep_vars3)]

#Check the linearity assumption for any continuous variables
visreg(final_model, "Estimated_Cost__Millions_", gg = TRUE, points = list(col = "black")) +
  geom_smooth(col = "red", fill = "red") + theme_bw() +
  labs(title = "Partial Residual Plot for Estimated Cost in Millions ",
       x = "Estimated Cost in Millions ", y = "Partial (deviance) Residuals")
#looks very good, almost perfectly linear

#checking for interactions among the main effects
final_model_int <- glm(Won ~   Sector2+ Estimated_Cost__Millions_ + 
                         Competitor_B + Competitor_E  +
                         Competitor_J+ Competitor_J*Competitor_E,
                       data = construction_train,
                       family = binomial(link = "logit"))
AIC(final_model)
AIC(final_model_int)
#interaction term is not significant
#AIC barely changing by adding interaction
#conclude: relationship is additive, not interactions necessary

#Check for influential observations 
plot(final_model, 4, id.n=6)
outlier_index = c(36,54,271,294,303,348) 
summary(as.data.frame(construction_train_keep3[outlier_index,]))
summary(construction_train_keep3)
#outlier group contains max Estimated_Cost__Millions_
#Estimated_Cost__Millions_ mean is nearly double in outliers
#competitor E bid everytime in outliers
#won 67% outliers vs 15% in full set

#dfbetas
influence.measures(final_model)

#loop that plots dfbeta for each predictor
for (i in colnames(construction_train_keep3)){
  dfbetasPlots(final_model, terms = i, id.n = 8,
               col = ifelse(insur_fit$y == 1, "red", "blue"))
}
outlier_index = c(3,9,23,44,54,59,73,131,133,134,141,150,164,201,257,271,
                  300,324,328,348,366,371)
summary(as.data.frame(construction_train_keep3[outlier_index,]))
summary(construction_train_keep3)
#mean Estimated_Cost__Millions_ 48% higher in outliers
#2.8 times as many bids won in outliers than full set


###########################################################################################################################
#########################   Validation for  final_model  ########################################

library(car)
library(gmodels)
library(forecast)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(descr)
library(sas7bdat)
library(brglm2)
library(visreg)
library(ggplot2)
library(tidyverse)
library(MASS)
library(ROCR)
library(DescTools)
library(Hmisc)

#Getting predicted probabilities
p<- predict(final_model, newdata = construction_valid, type="response")

#Calculate youdens Index
pred <- prediction(p, construction_valid$Won)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
classif_table <- data.frame(threshold = perf@alpha.values[[1]],
                            tpr = perf@y.values[[1]],
                            tnr = 1 - perf@x.values[[1]])
classif_table$youdenJ <- with(classif_table, 2*(.32*tpr + 0.68*tnr) - 1) #weighted tpr the same a tnr 
classif_table[which.max(classif_table$youdenJ),] # Find row with max
#row   threshold       tpr      tnr     youdenJ
#33 0.2969988 0.6785714 0.9029851 0.6623454

# Actual classification table (confusion Matrix)
df <- data.frame(y = construction_valid$Won,
                 phat = p)
df_new<- data.frame(y = construction_valid$Won,
                    yhat = p)
for (i in 1:length(df$phat)){
  if (df$phat[i]>= classif_table[which.max(classif_table$youdenJ),1]) {
    df_new$yhat[i]=1
  }
  else{
    df_new$yhat[i]=0
  }
}
xtabs(~ yhat+ y, data = df_new) 
#    y
#yhat  0   1
#0    121  9
#1    13  19


#Coefficient of Discrimination
D <- mean(fitted(final_model)[final_model$y== 1]) - mean(fitted(final_model)[final_model$y == 0])
D 
#discrimination - 0.3551441


# Check for c-statistic and Somer's D 
rcorr.cens(fitted(final_model), final_model$y)[-c(5, 6, 9)] # Ignoring unnecessary output
#   C Index            Dxy           S.D.              n Relevant Pairs     Concordant 
#    0.88088220     0.76176440     0.04387805   381.00000000 37996.00000000 33470.00000000 
# For all possible (1,0) pairs, the model assigned the higher predictive probability to the 1 88% of the time.


#Brier score calculation 
brier_score <- function(obj, new_x = NULL, new_y = NULL){
  if(is.null(new_y)){
    y <- obj$y
  } else {
    y <- new_y
  }
  p_obs <- mean(y)
  p <- predict(obj, newdata = new_x, type = "response")
  # brier score
  brier_score <- mean((y - p)^2, na.rm = TRUE)
  # max brier score is just the observed proportion
  brier_max <- p_obs*((1 - p_obs)^2) + (1 - p_obs)*(p_obs^2)
  # scaled brier score
  # ranges from 0 to 1---lower is better
  brier_scaled <- brier_score/brier_max
  # essentially, 1 - brier_scaled is the %improvement over null model
  res <- data.frame(brier_score = brier_score,
                    brier_max = brier_max,
                    brier_scaled = brier_scaled)
  res
}

brier_score(final_model, construction_valid, construction_valid$Won)
#brier_score brier_max brier_scaled
#    0.09605723  0.142966    0.6718886

### observed calibration curve
obs.phat <- data.frame(y = final_model$y, phat = fitted(final_model))
obs.phat <- arrange(obs.phat, phat)
ggplot(data = obs.phat) +
  geom_point(mapping = aes(x = phat, y = y), color = "black") +
  geom_smooth(mapping = aes(x = phat, y = y), color = "red") +
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = "black") +
  labs(x = "predicted probability", y = "observed frequency",
       title = "calibration curve") +
  scale_x_continuous(breaks = seq(0, 0.8, by = 0.1)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
  lims(x = c(0, 0.8), y = c(0, 1)) +
  theme_bw()

####ROC CURVES####
# then we can plot
plot(perf, colorize = TRUE)
# add 45-degree line (random guessing)
abline(a = 0, b = 1, lty = 2)
# AUC
auc <- performance(pred, measure = "auc")@y.values
auc
